[2023-03-09 11:44:37] DEBUG : Passed CLI Arguments : 
	regularization_strength=none 
	label_no_cyclone=-1.0 
	shuffle_buffer=32768 
	learning_rate=0.0001 
	batch_size=8192 
	patch_type=nearest 
	experiment=exp_3 
	activation=linear 
	augment=True={'left_right': <function coo_left_right at 0x7fff5b2f5f80>, 'up_down': <function coo_up_down at 0x7fff5b2fa050>, 'rot180': <function coo_rot180 at 0x7fff5b38c560>} 
	run_name=08_v5_tc_aug_exp_3_mae 
	network=model_v5 
	shuffle=True 
	epochs=500 
	cores=None 
	loss=mae
[2023-03-09 11:44:37] DEBUG : Program started
[2023-03-09 11:44:37] DEBUG : Train, valid and test data files loaded. We have 72 - 24 shard-files for training and validation.
[2023-03-09 11:45:32] DEBUG : Train, valid and test datasets loaded.
[2023-03-09 11:45:32] WARNING : Collective ops is not configured at program startup. Some performance features may not be enabled.
[2023-03-09 11:45:34] INFO : Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')
[2023-03-09 11:45:34] DEBUG : Mirrored strategy created with 4 devices
[2023-03-09 11:45:34] INFO : Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
[2023-03-09 11:45:34] INFO : Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
[2023-03-09 11:45:34] INFO : Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
[2023-03-09 11:45:34] INFO : Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
[2023-03-09 11:45:34] INFO : Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
[2023-03-09 11:45:34] INFO : Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
[2023-03-09 11:45:34] INFO : Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
[2023-03-09 11:45:34] INFO : Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
[2023-03-09 11:45:34] INFO : Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
[2023-03-09 11:45:34] INFO : Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
[2023-03-09 11:45:34] DEBUG : New model created
[2023-03-09 11:45:34] DEBUG : Model compiled
[2023-03-09 11:45:36] INFO : batch_all_reduce: 20 all-reduces with algorithm = nccl, num_packs = 1
[2023-03-09 11:45:39] INFO : batch_all_reduce: 20 all-reduces with algorithm = nccl, num_packs = 1
[2023-03-09 11:46:20] DEBUG : Creating converter from 5 to 3
[2023-03-09 14:04:02] DEBUG : Model trained
[2023-03-09 14:04:03] DEBUG : Saved training history
[2023-03-09 14:04:03] DEBUG : Saved run hyperparameters history
[2023-03-09 14:04:03] DEBUG : Process completed
